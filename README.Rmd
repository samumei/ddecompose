---
output:
  github_document:
    toc: true
    toc_depth: 3
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  width = 150
)
```


# `ddecompose`: Detailed Distributional Decompositions - Alt: An R Package for Decompositions of Distributional Differences 

<!-- badges: start -->
[![R-CMD-check](https://github.com/samumei/ddecompose/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/samumei/ddecompose/actions/workflows/R-CMD-check.yaml)
[![Codecov test coverage](https://codecov.io/gh/samumei/ddecompose/branch/master/graph/badge.svg)](https://app.codecov.io/gh/samumei/ddecompose?branch=master)
[![Lifecycle: stable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html#stable)
[![CRAN status](https://www.r-pkg.org/badges/version/ddecompose)](https://CRAN.R-project.org/package=ddecompose)
[![License: GPL (>= 3)](https://img.shields.io/badge/License-GPL%20%28%3E%3D%203%29-blue.svg)](https://choosealicense.com/licenses/gpl-3.0/)
<!-- badges: end -->


## Overview

The R package **ddecompose** implements the [Oaxaca (1973)](https://www.jstor.org/stable/2525981)-[Blinder (1973)](https://www.jstor.org/stable/144855) decomposition method and generalizations
of it that decompose differences in distributional statistics beyond the mean.

`ob_decompose()` decomposes differences in the mean outcome between two groups into one 
part explained by different covariates (composition effect) and into 
another part due to differences in linear regression coefficients linking 
the covariates to the outcome variable (structure effect). The function further
divides the two effects into the contribution of each covariate and allows for 
weighted 'doubly robust' decompositions. For distributional statistics beyond
the mean, the function performs the RIF decomposition of [Firpo, Fortin, and Lemieux (2018)]( https://doi.org/10.3390/econometrics6020028). 

`dfl_decompose()` divides differences in distributional statistics into an
composition effect and a structure effect using inverse probability
weighting as proposed by [DiNardo, Fortin, and Lemieux (1996)](https://www.jstor.org/stable/2171954). The function also allows
to sequentially decompose the composition effect into the contribution of
single covariates.

The package contains generic summary, print and plot functions for the results
and computes standard errors. This documentation provides a brief 
overview of the functions implemented in the package. For a more detailed 
discussion of decomposition methods, including their respective assumptions and 
limitations, refer to [Fortin, Lemieux, and Firpo (2011)](https://economics.ubc.ca/wp-content/uploads/sites/38/2013/05/pdf_paper_nicole-fortin-decomposition-methods.pdf) and Firpo et al. (2018). 

In contrast to the existing **oaxaca** ([Hlavac, 2022](https://cran.r-project.org/web/packages/oaxaca/vignettes/oaxaca.pdf)), 
**ddecompose** is not limited to decomposition of mean differences and offers
'doubly robust' decompositions. The packages also complements **Counterfactual** ([Chen et al., 2017](https://journal.r-project.org/archive/2017/RJ-2017-033/RJ-2017-033.pdf)) 
that models conditional distribution functions instead of using inverse probability
weighting to perform aggregate decompositions beyond the mean.

## Installation 

You can hopefully soon install the CRAN version of `ddecompose`
```{r eval=FALSE}
install.packages("ddecompose")
```

Until now, refer to the latest development version from GitHub:
```{r , eval=FALSE}
install.packages("devtools")
devtools::install_github("samumei/ddecompose")
```


## Background

### Oacaxa-Blinder Decomposition

The original decomposition method introduced by Oaxaca (1973) and Blinder (1973) divides the difference in the mean of an outcome variable (e.g., hourly wages)
between two groups $g = 0, 1$ into a part explained by differences in the 
mean of the covariates (e.g., educational level or experience) and into 
another part due to different linear regression coefficients (e.g., returns to education)
that link the covariates to the outcome variable. 

The method linearly models the relationship between the outcome $Y$ and covariates
$X$
$$Y_{g,i} = \beta_{g,0} + \sum^K_{k=1}X_{k,i}\beta_{g,k} + \varepsilon_{g,i},$$
where $\beta_{g,0}$ is the intercept and $\beta_{g,k}$ are the slope coefficients of
covariates $k = 1,\ldots, K$. Moreover, it is assumed that the error
term $\varepsilon$ is conditionally independent of $X$, i.e., 
$E( \varepsilon_{g,i} | X_{1,i}, \ldots ,X_{k,i}) = 0$, and that there is
an overlap in observable characteristics across groups ('common support'). 

The coefficients are estimated with OLS. Together with the sample means
of the covariates, one can derive a counterfactual mean  
$$\overline Y_C = \widehat \beta_{0,0} + \sum^K_{k=1}\overline X_{1,k} \widehat \beta_{0,k}$$
that would be observed if group $1$ had the same coefficients like group $0$. By 
adding and subtracting the counterfactual, the observed difference
$$\widehat\Delta^\mu_O = (\overline Y_1 - \overline Y_C) + (\overline Y_C - \overline Y_0) = \widehat\Delta^\mu_S + \widehat\Delta^\mu_C, $$

is divided into the aggregate structure effect 
$$\widehat\Delta^\mu_S  = (\widehat \beta_{1,0} - \widehat \beta_{0,0}) + \sum^K_{k=1}\overline X_{1,k}(\widehat \beta_{1,k} - \widehat \beta_{0,k}),$$


that captures outcome differences due to different coefficients, and the composition effect 
$$\widehat\Delta^\mu_X = \sum^K_{k=1} (\overline X_{1,k} - \overline X_{0,k})\widehat \beta_{0,k}, $$

which accounts for mean differences of the covariates. Note that
we could also combine the coefficients from group 1 with the covariates of group 
0 to define a counterfactual. Such a change in the “reference” group generally
leads to different results.

$\widehat\Delta^\mu_S$ and $\widehat\Delta^\mu_X$ denote the aggregate composition
terms. Since the method hinges on an additive linear model, the terms can be further
divided into the contribution of each covariate $k$ in a *detailed
decomposition*. For instance, the contribution of covariate $k = 1$ to the 
structure effect is $\overline X_{1,1}(\widehat \beta_{1,1} - \widehat \beta_{0,1})$, 
while $(\overline X_{1,1} - \overline X_{0,1})\widehat \beta_{0,1}$ is the covariate's
contribution to the composition effect.

### Reweighting Decomposition

The Oaxaca-Blinder decomposition is limited to the mean. Moreover, the 
decomposition terms are biased if the expectation of the outcome conditional
on the covariates is not linear (see [Barsky et al., 2002](https://www.jstor.org/stable/3085702)). DiNardo, Fortin, and Lemieux (1996), DFL hereafter, propose an alternative approach that overcomes both shortcomings. Instead of modelling the conditional mean, the method uses 
inverse probability weighting to estimate a counterfactual outcome distribution
that combines the conditional outcome distribution of one group and the covariates
distribution of the other group.  For instance, if we are interested in the 
outcomes of group 0 with covariates of group 1, we would reweight the outcome
distribution of group 0 such that its covariates distribution matches that of group 1
$$F_{Y_C}(y) = \int F_{Y_0}(y|x)dF_{X_1} (x)= \int F_{Y_0}(y|x)\Psi_X(x)dF_{X_0}(x).$$

By applying Bayes' rule, the reweighting factor,
$$\Psi_X(x) = \frac{dF_{X_1}(x)}{dF_{X_0}(x)} = \frac{P(g=0)P(g=1|x)}{P(g=1)P(g=0|x)},$$ 

can be expressed in terms of $P(g)$ and $P(g|x)$, the (conditional) probabilities of
belonging to group $g$. This allows us to estimate the reweighting factor using sample 
probabilities of each group and fitting conditional probability models (e.g.,
logit) in the joint sample. The estimated factors are then used to estimate weighted 
distributional statistics of interest (e.g., mean, quantiles or Gini coefficient) in 
the reference sample -- group 0 in the present example. The resulting counterfactual
distributional statistic, $\widehat\nu_C=\widehat\nu(F_{Y_C})$, is then contrasted 
with the observed difference
$$\widehat\Delta_O^{\nu} = (\widehat\nu_1 - \widehat\nu_C) + (\widehat\nu_C - \widehat\nu_0) = \widehat\Delta_S^\nu + \widehat\Delta_X^\nu,$$

which yields again an aggregate structure effect and aggregate composition effect.

The two decomposition terms account for the contribution of the covariates and of the
conditional outcome distribution, respectively, assuming common support and ignorability.
The latter condition asserts that the distribution of unobserved covariates $\varepsilon$ conditional on observed covariates $X$ is independent of group $g$.


### Sequential Decomposition

In contrast to the Oaxaca-Blinder decomposition, where the contributions of each
covariate simply add up, detailed decompositions are not straightforward in the
reweighting framework. However, DFL show that we can sequentially alter the covariates
distributions to decompose the composition effect into the contribution of single
covariates. For instance, assume we want to distinguish the effect of covariate $X_1$ 
(e.g., union status) from that of covariate $X_2$ (e.g., industry).
We begin again with the counterfactual distribution based on the conditional
outcome distribution of group 0 and the covariates distribution of group 1 
$$F_{Y_{C}}(y) = \iint F_{Y_0}(y|x_1,x_2)dF_{X_{1,1}}(x_1|x_2)dF_{X_{1,2}}(x_2)$$

and introduce a second counterfactual where we combine the 
conditional outcome distribution of group 0 as well as the conditional covariate 
distribution of $X_1$ given $X_2$ (e.g., union coverage by industry) of
group 0 with the covariates distribution $X_2$ (e.g., employment by industry) of group 1
$$F_{Y_{C,X_2}}(y) = \iint F_{Y_0}(y|x_1,x_2)dF_{X_{0,1}}(x_1|x_2)dF_{X_{1,2}}(x_2) $$

which can be expressed as the outcome distribution 0
$$F_{Y_{C,X_2}}(y) = \iint F_{Y_0}(y|x_1,x_2)dF_{X_{0,1}}(x_1|x_2)\Psi_{X_2}(x_2)dF_{X_{0,2}}(x_2),$$
reweighted by the factor
$$\Psi_{X_2}(x_2) = \frac{dF_{X_{1,2}}(x_2)}{dF_{X_{0,2}}(x_2)} =  \frac{P(g=0)P(g=1|x_2)}{P(g=1)P(g=0|x_2)}.$$

With the distributional statistics of the additional counterfactual, we can 
divide the aggregate decomposition effect into the contribution of each covariate
$$\widehat \Delta_X^{\nu} =  (\widehat \nu_C - \widehat \nu_{C,X_2}) + (\widehat \nu_{C,X_2} - \widehat \nu_0) = \widehat \Delta_{X_1}^\nu + \widehat \Delta_{X_2}^\nu.$$


Sequential decompositions are path dependent because the detailed composition
effects attributed to single covariates depend on the order of which we include the 
variables into the sequence. For instance, it matters if we reweight union coverage
by industry $F(x_1|x_2)$ or the industry employment given union coverage
$F(x_2|x_1)$.

Moreover, we get different results if we do not combine the marginal covariate 
distribution $X_2$ (e.g., industry employment) of group 1 with the conditional
distribution of $X_1$ given $X_2$ (e.g., union density by industry) of group 0 but
rather, combine the marginal of group 0 with the conditional distribution of group 1
to derive the counterfactual, e.g.,
$$F_{Y_{C,X_1}}(y) = \iint F_{Y_0}(y|x_1,x_2)dF_{X_{1,1}}(x_1|x_2)dF_{X_0,2}(x_2).$$
where we would reweight group 0 with a slightly different factor 
$$\Psi_{X_1}(x_1,x_2) = \frac{dF_{X_{1,1}}(x_1|x_2)}{dF_{X_{0,1}}(x_1|x_2)} =  \frac{P(g=0|x_2)P(g=1|x_1,x_2)}{P(g=1|x_2)P(g=0|x_1,x_2)}.$$

### 'Doubly Robust' Oaxaca-Blinder Decomposition

A robust and path independent alternative for detailed decompositions at the mean 
is to combine DFL reweighting with the linear Oaxaca-Blinder method (see 
Fortin et al., 2011: 48-51). This approach has the valuable side effect of 
accounting for potential errors introduced by an incomplete inverse probability 
weighting and the linear model specification, respectively.

The estimation proceeds in two steps. First, the reweighting function $\widehat\Psi_X(x)$, which matches the characteristics of group $0$ (if group 0 is the reference group) to those of group $1$, is derived. Second, the linear model and the covariate means are estimated in the two observed samples as well as in the reweighted sample $0$. We denote the estimates of the reweighted sample as $\widehat \beta_{C,0}$, $\widehat \beta_{C,k}$, and $\overline X_{C,k}$.

The mean of the reweighted sample builds the main counterfactual to derive the aggregate structure and composition effects, respectively. The detailed decomposition terms are also evaluated with respect to the statistics of the reweighted sample, i.e., 

$$\widehat\Delta^\mu_{O,R} = (\widehat \beta_{1,0} - \widehat \beta_{C,0}) + \sum^K_{k=1} (\overline X_{1,k}\widehat \beta_{1,k} - \overline X_{C,k}\widehat \beta_{C,k}) + \sum^K_{k=1} (\overline X_{C,k}\beta_{C,k} - \overline X_{0,k}\widehat \beta_{0,k}) = \widehat\Delta^\mu_{S,R}  + \widehat\Delta^\mu_{X,R}.$$
These decomposition terms can be further decomposed into a structure and into a composition effect, respectively. This separates the errors from reweighting $\widehat\Delta^\mu_{S,e}$ and the linear specification $\widehat\Delta^\mu_{X,e}$, respectively, and yields a “pure” composition effect $\widehat\Delta^\mu_{X,p}$ and a “pure” structure effect $\widehat\Delta^\mu_{S,p}$ for each covariate. 

Specifically, the structure effect can be written as

$$\widehat\Delta^\mu_{S,R} = (\widehat \beta_{1,0} - \widehat \beta_{C,0}) + \sum^K_{k=1}\overline X_{1,k}(\widehat \beta_{1,k} - \widehat \beta_{C,k}) + \sum^K_{k=1} (\overline X_{1,k} - \overline X_{C,k})\widehat \beta_{C,k} = \widehat\Delta^\mu_{S,p} + \widehat\Delta^\mu_{S,e}.$$

By comparing $\beta_{1,k}$ to the coefficients of the reweighted group $0$, $\widehat \beta_{C,k}$, a “pure” structure effect adjusted for the reweighting error, $\widehat\Delta^\mu_{S,p}$, can be identified. Moreover, the reweighting error, $\widehat\Delta^\mu_{S,e}$, indicates how accurately the reweighting function $\widehat\Psi(X_i)$ reweights the covariates distribution of group $0$ to that of group $1$. If the composition of group $1$ is equal to the reweighted group $0$, the reweighting error is zero.

Similarly, the additional decomposition of the composition effect reads as

$$\widehat\Delta^\mu_{X,R} = \sum^K_{k=1} (\overline X_{C,k} - \overline X_{0,k})\widehat \beta_{0,k} + (\widehat \beta_{C,0} - \widehat \beta_{0,0}) + \sum^K_{k=1}\overline X_{C,k}(\widehat \beta_{C,k} - \widehat \beta_{0,k}) = \widehat\Delta^\mu_{X,p} + \widehat\Delta^\mu_{X,e}.$$

The specification error, $\widehat\Delta^\mu_{X,e}$, measures the extent to which the estimated coefficients change due to a different distribution of covariates if the (wage) structure remains the same. Thereby, the “pure” effect, $\overline X_{C,k} - \overline X_{0,k}$, for each covariate can be estimated, summing to the aggregate pure structure effect, $\widehat\Delta^\mu_{X,p}$. If the model is truly linear, i.e., correctly specified, $\beta_C$ of the reweighted group $0$ will be identical to $\beta_0$ and the specification error will be zero (Fortin et al. 2011, p. 49-50). 

The reweighted OB decomposition is "doubly robust" as it yields consistent estimates
even if either the linear model or the reweighting estimator is misspecified. In
contrast to the simple reweighting or linear approach it does not hinge on a single 
correctly specified model. While the reweighted OB decomposition is doubly robust 
and path independent, it is limited to the mean.


### Reweighted RIF Regression Decomposition 

A path independent method that goes beyond the mean is the RIF decomposition 
of Firpo, Fortin, and Lemieux (2018). The approach approximates the expected value
of the 'recentered influence function' (RIF) of the distributional statistic (e.g., quantile, variance, or Gini coefficient) of an outcome variable conditional on covariates with linear regressions. RIF regression coefficients can be consistent estimates of the marginal effect 
of a small change in the expected value of a covariate to the distributional statistics of 
an outcome variable (see [Firpo et al., 2009a](https://www.econometricsociety.org/publications/econometrica/2009/05/01/unconditional-quantile-regressions) and the documentation of the companion package [`rifreg`](https://github.com/samumei/rifreg)). Thus, they can be used to decompose between-group difference in distributional statistics. Firpo et al. (2018) combine the RIF regressions again 
with the reweighting estimator to avoid specification errors. 

First, the approach computes the recentered influence function (RIF) of the outcome variable $Y$ and a distributional statistic of interest $\nu$. Then, an OLS regression of the transformed outcome variable $Y$ is run on the explanatory variables $X$. Thereafter, the decomposition method is analogous to the original OB method:

$$\widehat\Delta^\nu_{O,R} =  \widehat\Delta^\nu_{S,p} + \widehat\Delta^\nu_{S,e} + \widehat\Delta^\nu_{X,p} +  \widehat\Delta^\nu_{X,e}.$$ 
With $\widehat\Delta^\nu_{S,p}$ and $\widehat\Delta^\nu_{S,e}$ estimating the pure structure effect and the reweighting error as

$$\widehat\Delta^\nu_{S,R} =  \widehat\Delta^\nu_{S,p} + \widehat\Delta^\nu_{S,e} = (\widehat \beta_{1,0} - \widehat \beta_{C,0}) + \sum^K_{k=1}\overline X_{1,k}(\widehat \beta_{1,k} - \widehat \beta_{C,k}) + \sum^K_{k=1} (\overline X_{1,k} - \overline X_{C,k})\widehat \beta_{C,k}$$

and $\widehat\Delta^\nu_{X,p}$ and $\widehat\Delta^\nu_{X,e}$ estimating the pure coefficient effect and the specification error: 

$$\widehat\Delta^\nu_{X,R} = \widehat\Delta^\nu_{X,p} + \widehat\Delta^\nu_{X,e} = \sum^K_{k=1} (\overline X_{C,k} - \overline X_{0,k})\widehat \beta_{0,k} + (\widehat \beta_{C,0} - \widehat \beta_{0,0}) + \sum^K_{k=1}\overline X_{C,k}(\widehat \beta_{C,k} - \widehat \beta_{0,k})$$
with the RIF regression coefficients $\widehat \beta$ and the covariate means $\overline X$ of groups
$0$, $1$, and $C$, the reweighted reference group 0, respectively. 

Again, the specification error increases if the conditional expectation of the RIF
is not well approximated by the linear model. Moreover, as the RIF regression coefficients
capture the marginal effects of small location shifts in the covariates distribution on the
distributional statistic of the outcome variable, the specification error can
be large if the location shifts are substantial or if the between-group differences 
in the covariates distribution relate to higher moments or the dependence structure
among the covariates (see also [Rothe, 2012: 16-19](https://docs.iza.org/dp6397.pdf) or [Rothe, 2015: 328](https://doi.org/10.1080/07350015.2014.948959)).

### Inference

Analytical standard errors are straightforward for the Oaxaca-Blinder decomposition
under the assumption of independence between the groups (see Jann, [2005](https://boris.unibe.ch/69506/1/oaxaca_se_handout.pdf) and [2008](https://journals.sagepub.com/doi/abs/10.1177/1536867X0800800401)). [Firpo (2007)](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0262.2007.00738.x) and 
[Firpo and Pinto (2016)](https://www.jstor.org/stable/26609621) develop asymptotic theory
for the reweighting estimator. [Firpo, Fortin, and Lemieux  (2009b)](https://www.econometricsociety.org/publications/econometrica/2009/05/01/unconditional-quantile-regressions/supp/6822_extensions_0.pdf) and Firpo et al. (2018) do the same for the RIF estimator and for the RIF decomposition terms, respectively. The authors propose to bootstrap standard errors. `ddecompose` allows bootstrapping standard errors in both `ob_decompose()` and `dfl_decompose()`. For the linear Oaxaca-Blinder decomposition, analytical standard errors are available, too.


## Examples 

The following examples illustrate the operation of the main decomposition functions in `ddecompose`. We use a sample from the National Longitudinal Survey (NLSY) 79 containing wage data from the year 2000 for workers who aged 35 to 43. The data are from O'Neill and O'Neill (2006) and were used to illustrate the Oaxaca-Blinder mean decomposition in Fortin, Lemieux, and Firpo (2011). The data contains 2655 male and 2654 female observations, respectively.

```{r eval = TRUE} 
library(ddecompose)
data("nlys00")
```


### Oaxaca-Blinder Decomposition 

We decompose the gender wage gap into composition and structure effect, using Oaxaca-Blinder decomposition without reweighting. We specify a wage regression model and then run the estimation. 

```{r eval = FALSE}
model <- log(wage) ~  age + region + education + 
                        years_worked_civilian + years_worked_military + 
                        part_time + family_responsibility + industry 

gender_gap_decomposition <- ob_decompose(formula = model,
                                        data = nlys00,
                                        group = female)
```

Per default, the function subtracts the mean of the lower rank group from
the mean of the higher rank group to calculated the overall difference and 
uses the coefficients of the lower ranked group to calculated the counterfactual. 
In the present example, `yes` is the reference level and lower ranked value of
the factor variable `female`. Thus, the female mean is subtracted from the male 
mean and the female coefficients are used to estimate the counterfactual mean.

```{r eval = TRUE}
levels(nlys00$female)
```

If we want to change the reference group, i.e., use male coefficient to estimate
the counterfactual, we have to change the parameter `reference_0 = FALSE` and 
that the higher ranked group is used as reference. To change the direction of 
the subtraction, you could alter the parameter `subtract_1_from_0`. 

```{r eval = TRUE}
gender_gap_decomposition <- ob_decompose(formula = model,
                                             data = nlys00,
                                             group = female, 
                                             reference_0 = FALSE)
```

With `summary()`, we can display the decomposition formula and the estimation results.
For Oaxaca-Blinder decompositions, the function displays per default heteroscedasticity-robust standard errors under the assumption of independence between the groups.
```{r eval=TRUE}
summary(gender_gap_decomposition)
```

`ddecompose` comes with a handy plotting function. To plot the overall composition
and structure effects, we need to set `detailed_effects = FALSE`.

```{r eval=TRUE}
plot(gender_gap_decomposition, detailed_effects = FALSE)
```

Note that detailed decompositions with factor variables depend on the factor's
left-out reference level or base group. `ob_decompose` allows to normalize factor
variables with the approach of Gardeazabal and Ugidos (2004) by setting 
`normalize_factors = TRUE` to get detailed decompositions that are independent
of the reference level.

We can aggregate the detailed effects displayed in the `summary()` and `plot()` function. For example, if we want to separate personal and contextual factors that explain the wage gap, we can aggregate these variables in a list.

```{r eval=TRUE}
custom_aggregation <- list(`Personal Factors` = c("age", 
                                                  "education<10 yrs", 
                                               "educationHS grad (diploma)",
                                               "educationHS grad (GED)",
                                               "educationSome college",
                                               "educationBA or equiv. degree",
                                               "educationMA or equiv. degree",
                                               "educationPh.D or prof. degree",
                                               "part_time",
                                               "family_responsibility"), 
                           `Experience` = c("years_worked_civilian",
                                            "years_worked_military"), 
                           `Contextual Factors` = c("regionNorth-central",
                                                 "regionSouth",
                                                 "regionWest",
                                                 "industryManufacturing",
                                                 "industryEducation, Health, Public Admin.",
                                                 "industryOther services"))

plot(gender_gap_decomposition, 
     custom_aggregation = custom_aggregation)
```


### 'Doubly Robust' Decompostion

To estimate 'doubly robust'  decomposition, we can add reweighting to the decompostion. Thereby, we also estimate the specification and reweighting error. By default, the same covariate
specification is used for the outcome model as for the conditional probability model used
to derive the reweighting factors. However, it is advisable to add a more flexible reweighting model, taking interactions into account. The reweighting formula is added to the decomposition formula, separated by the `|` operator. 

For decomposition based on reweighting, standard errors need to be bootstrapped. By 
increasing the number of `cores` the bootstrap replications are computed on, we 
can reduce computation time. Per default, 100 bootstrap replications are calculated. 

```{r eval = TRUE}

model_w_reweighting <- log(wage) ~  
                           age + region + education + 
                           years_worked_civilian + years_worked_military + 
                           part_time + family_responsibility + industry |
                           age + region + education + 
                           years_worked_civilian + years_worked_military + 
                           part_time + family_responsibility + industry +
                           education:region + age:education 


gender_gap_decomposition_w_reweighting <- 
    ob_decompose(formula = model_w_reweighting,
                 data = nlys00,
                 group = female, 
                 reference_0 = FALSE,
                 reweighting = TRUE, 
                 bootstrap = TRUE, 
                 cores = 4)
```


The default method for fitting and predicting conditional probabilities, used to derive the reweighting factor, is a logit model. However, you can also use `reweighting_method = "fastglm"` fitting a logit model with the fast algorithm of **fastglm**, or `random_forest`
that estimates the conditional probabilities with the **ranger** implementation of random forest.

Setting `trimming = TRUE` will trim observations with dominant reweighting factor values. By default, reweighting factor values are trimmed according to the rule of Huber, Lechner, and Wunsch (2013). Thereby, the `trimming_threshold`, i.e., the maximum accepted relative weight of the reweighting factor value (inverse probability weight) of a single observation, is set to `sqrt(N)/N`, where `N` is the number of observations in the reference group. The trimming threshold can also be manually set to a numeric value. 

If we add reweighting, the `plot()` and `summary()` functions will also display the specification and reweighting error. 


### RIF Regression Decomposition

To decompose group differences beyond the mean with `ob_decompose` we use RIF regressions. In the following examples, we will analyze the changes in wage inequality between 1983/85 and 2003/05 and assess which covariates contribute to explaining these changes. First, we look at the changes in the variance. Then, we decompose the wage gap at each decile. We use a subsample of the CPS data
used in the handbook chapter of Fortin, Lemieux, & Firpo (2011).

```{r eval = TRUE, warning = FALSE}

data("men8305")

model_rifreg <- log(wage) ~ union*(education + experience) + education*experience 

# Variance
variance_decomposition <- ob_decompose(formula = model_rifreg,
                 data = men8305,
                 group = year, 
                 reweighting = TRUE, 
                 rifreg_statistic = "variance",
                 bootstrap = TRUE, 
                 cores = 4)

# Deciles
deciles_decomposition <- ob_decompose(formula = model_rifreg,
                 data = men8305,
                 group = year, 
                 reweighting = TRUE, 
                 rifreg_statistic = "quantiles",
                 rifreg_probs = c(1:9)/10,
                 bootstrap = TRUE, 
                 cores = 4)

# Plotting the deciles
plot(deciles_decomposition)

```

The RIF functions for the following statistics are currently implemented: `"quantiles"`, `"mean"`, `"variance"`, `"gini"`, `"interquantile_range"`, and `"interquantile_ratio"`. However, `ob_decompose` also allows you to pass a custom RIF function for the decomposition, by setting `rifreg_statistic = "custom"` and passing the custom function to `custom_rif_function`. [Cowell and Flachaire (2007)](https://doi.org/10.1016/j.jeconom.2007.01.001), [Essama-Nssah & Lambert (2012)](https://doi.org/10.1108/S1049-2585(2012)0000020009), and [Rios-Avila (2020)](https://doi.org/10.1177/1536867X20909690) derive the influence functions for an array of distributional statistics. More information about RIF regressions can be found in the documentation of the companion package [`rifreg`](https://github.com/samumei/rifreg).  

Custom RIF functions must specify a `dep_var` parameter for the outcome variable $Y$, `weights` for potential sample weights, and `probs` defining the corresponding probabilities of quantiles. If they are not needed, they must be set to `NULL` in the function definition (e.g., `probs = NULL`).

The following example shows how to write the RIF for the top 10 percent income share and, then, to estimate the RIF regression decomposition using this custom function. The formula for this specific RIF can be found in Essam-Nssah & Lambert (2012) or Rios-Avila (2020).

```{r eval = TRUE}

# custom RIF function for top 10% percent income share
custom_top_inc_share <- function(dep_var,
                                 weights,
                                 probs = NULL,
                                 top_share = 0.1) {
  top_share <- 1 - top_share
  weighted_mean <- weighted.mean(
    x = dep_var,
    w = weights
  )
  weighted_quantile <- Hmisc::wtd.quantile(
    x = dep_var,
    weights = weights,
    probs = top_share
  )
  lorenz_ordinate <- sum(dep_var[which(dep_var <= weighted_quantile)] *
    weights[which(dep_var <= weighted_quantile)]) /
    sum(dep_var * weights)
  if_lorenz_ordinate <- -(dep_var / weighted_mean) * lorenz_ordinate +
    ifelse(dep_var < weighted_quantile,
      dep_var - (1 - top_share) * weighted_quantile,
      top_share * weighted_quantile
    ) / weighted_mean
  rif_top_income_share <- (1 - lorenz_ordinate) - if_lorenz_ordinate
  rif <- data.frame(rif_top_income_share, weights)
  names(rif) <- c("rif_top_income_share", "weights")
  return(rif)
}

custom_decomposition <- ob_decompose(formula = model_rifreg,
                 data = men8305,
                 group = year, 
                 reweighting = TRUE, 
                 rifreg_statistic = "custom",
                 custom_rif_function = custom_top_inc_share,
                 bootstrap = TRUE, 
                 cores = 4)

plot(custom_decomposition)

```




### Reweighting Decomposition

Now, we present the use of the other main function: `dfl_decompose()`. Fortin, Lemieux, and Firpo (FLF, 2011, p. 79-88) decompose the increase in U.S. male wage inequality between the early 1980s and the early 2000s using the CPS data. In this example, we perform the same decomposition on 
subsample of the original data. We treat the observations from 1983 to 1985 as the reference group, which is then reweighted. The formula defines on the left-hand side the outcome variable
and specifies on the right-hand side the conditional probability model.

```{r eval = TRUE}
library(ddecompose)
data("men8305")

flf_model <- log(wage) ~ union*(education + experience) + education*experience
flf_male_inequality  <- dfl_decompose(flf_model, 
                                  data = men8305,
                                  weights = weights,
                                  group = year, 
                                  bootstrap = TRUE, 
                                  cores = 1)
```

We can summarize the results:
```{r eval = TRUE}
summary(flf_male_inequality)
```

Using `plot()`, we can illustrate the decomposition across different quantiles.
```{r eval = TRUE}
plot(flf_male_inequality)
```


## Replication of Firpo, Fortin, and Lemieux (2018)

To validate the functions and provide users with an additional example, we replicate the reweighted RIF regression decomposition estimates in Firpo et al. (2018, p. 30). In their empirical example, Firpo et al. focus on changes in wage inequality in the US between 1988 and 2016. Using a large sample of male log wages in 1988-1990 (268,494 observations) and in 2014-2016 (236,296 observations) based on the Outgoing Rotation Group (ORG) supplement of the Current Population Survey (CPS), the authors attribute changes in several wage inequality measures (i.e, variance, Gini coefficient, and interquantile ranges) between the two time periods to changes in the composition (e.g., union coverage, education, and experience) and changes in the wage structure. 

This replication follows the Stata replication code, that the authors published alongside the paper and that is available on one author's [website](https://sites.google.com/view/nicole-m-fortin/data-and-programs) and [here](https://drive.google.com/file/d/1sab0RuBPRmch3DhreTraQj_3nUBwGMEJ/view). High wages in the public CPS dataset are top-coded due to privacy concerns. The Firpo et al. impute these wages using a random drawas from a Pareto distribution. Since random numbers are generated differently in R and Stata, even with an equivalent seed, we perform all data preparation in Stata up to the estimation of the decomposition in Stata, i.e., the "oaxaca" commands in stata. This ensures that changes in the estimation results between our function and the original paper are not due to different input data. 

To reproduce the code below, be sure to download the entire dataset and Stata code from the journal's website, execute the code up to the oaxaca command, save the data, and load it into your R environment. 

### Loading Data

```{r eval=FALSE}
# Make sure you execute the Stata Code until the "oaxaca" commands 
# and save the data in the appropriate folder.
men8816_t4 <- readstata13::read.dta13("data-raw/usmen8816_t4.dta")

# Removing redundant observations - we replicate the reweighting within the function
men8816_t4 <- men8816_t4[men8816_t4$time <= 1,] 
```


### Reweighted RIF Regression Decomposition (Table 4)

The model is specified as in the Stata files. We use sample weights, compute bootstrapped standard errors with 100 iterations, and use the Epanechnikov kernel with a fixed bandwidth of 0.06 in density estimation required to derive the RIF of the interquantile ranges.

```{r eval=FALSE}

set.seed(987421)

ffl_model_with_reweighting <- as.formula(
    paste("lwage2 ~ covered + nonwhite + nmarr + 
          ed0 + ed1 + ed3 + ed4 + ed5 + ",
          paste(grep(paste0("^ex(", paste(c(1:4, 6:9), collapse = "|"), ")$"), 
                     names(men8816_t4), value = T), collapse = " + "), " + ",
          paste(grep(paste0("^occd(", paste(c(11:60, 80:91), collapse = "|"), ")$"),
                     names(men8816_t4), value = T), collapse = " + "), " + ",                     
          paste(grep(paste0("^indd(", paste(c(1, 3:14), collapse = "|"), ")$"), 
                     names(men8816_t4), value = T), collapse = " + "), " + pub | ",
          paste("covered + nonwhite +",
                paste(grep("^marr", 
                           names(men8816_t4), value = TRUE), collapse = " + "), "+",
                paste(c("ed0", "ed1", "ed3", "ed4", "ed5"), collapse = " + "), "+",
                paste(grep("^ex[1-4]|^ex[6-9]", 
                           names(men8816_t4), value = TRUE), collapse = " + "), "+",
                paste(grep("^uned", 
                           names(men8816_t4), value = TRUE), collapse = " + "), "+",
                paste(grep("^unex", 
                           names(men8816_t4), value = TRUE), collapse = " + "), "+",
                paste(grep("^ex[1-9]ed", 
                           names(men8816_t4), value = TRUE), collapse = " + "), "+",
                paste(grep("^pub", 
                           names(men8816_t4), value = TRUE), collapse = " + "), "+",
                paste(grep("^indd(1|1e|[3-9]|10|11|13|14)(?!2)", 
                           names(men8816_t4), perl = TRUE, value = TRUE), collapse = " + "), "+",
                paste(grep("^occd", names(men8816_t4), value = TRUE), collapse = " + "))))


# Interquantile Ratio 90-10 
decompose_90_10  <- ob_decompose(formula = ffl_model_with_reweighting,
                                data = men8816_t4,
                                weights = eweight,
                                group = time,
                                reference_0 = TRUE,
                                rifreg_statistic = "interquantile_range",
                                rifreg_probs = c(0.9, 0.1),
                                bw = 0.065,
                                kernel = "epanechnikov",
                                reweighting = TRUE,
                              reweighting_method = "fastglm",
                                trimming = TRUE,
                                trimming_threshold = 100,
                                bootstrap = TRUE,
                                bootstrap_iterations = 100)
## Variance
set.seed(23904875)
decompose_variance  <- ddecompose::ob_decompose(formula = ffl_model_with_reweighting,
                                 data = men8816_t4,
                                 weights = eweight,
                                 group = time,
                                 reference_0 = TRUE,
                                 rifreg_statistic = "variance",
                                 reweighting = TRUE,
                              reweighting_method = "fastglm",
                                 trimming = TRUE,
                                 trimming_threshold = 100,
                                 bootstrap = TRUE,
                                 bootstrap_iterations = 100)

## Gini 

# Updating the model
gini_model_raw <- update(ffl_model_with_reweighting, exp(.) ~ .)
gini_model_character <- as.character(gini_model_raw)
gini_model_split <- strsplit(gini_model_character, "~")
ffl_model_with_reweighting_gini <- 
  as.formula(paste(gini_model_split[[2]], "~",
                   gsub("\\(|\\)", "", gini_model_split[[3]][1])))

set.seed(130234976)
decompose_gini  <- ddecompose::ob_decompose(formula = ffl_model_with_reweighting_gini,
                               data = men8816_t4,
                               weights = eweight,
                               group = time,
                               rifreg_statistic = "gini",
                               reweighting = TRUE,
                              reweighting_method = "fastglm",
                               trimming = TRUE,
                               trimming_threshold = 100,
                               bootstrap = TRUE,
                               bootstrap_iterations = 100, 
                              cores = 1)

```

```{r eval=TRUE, echo=FALSE}

load("data-raw/decompose_90_10.rda")
load("data-raw/decompose_variance.rda")
load("data-raw/decompose_gini.rda")

```


### Discussion of Results

```{r eval=TRUE}
# Presenting the results
variables <- decompose_variance[["variance"]][["decomposition_terms"]][["Variable"]]

ffl_aggregation <- list(`Union` = "covered", 
                        `Other` = c("nonwhite", "nmarr", 
                                    grep("ex", variables, value = TRUE)),
                        `Education` = grep("ed[0-9]", variables, value = TRUE), 
                        `Occupation` = grep("occd", variables, value = TRUE), 
                        `Industry` = grep("indd", variables, value = TRUE))

summary(decompose_90_10, custom_aggregation = ffl_aggregation)
summary(decompose_variance, custom_aggregation = ffl_aggregation)
summary(decompose_gini, custom_aggregation = ffl_aggregation)

```

The results presented below are similar to those in Table 4 of Firpo et al. (2018, p. 30). However, some of the coefficients calculated here differ slightly from the results in the paper. There are several reasons for these differences.

1. Reweighting: An important difference is the reweighting factors. Firpo et al. use the entire dataset to compute the reweighting factors. However, for the decomposition they remove very high wages from the dataset. In `ob_decompose()`, the same (trimmed) dataset is used for reweighting and the decomposition estimation.

2. Different decomposition formula: In the paper, the formula presented for the pure structure and reweighting errors is identical to the formula presented in the background section above. For instance, the pure wage structure effect is computed as $(\widehat \beta_{1,0} - \widehat \beta_{C,0}) + \sum^K_{k=1}\overline X_{1,k}(\widehat \beta_{1,k} - \widehat \beta_{C,k})$. However, the Stata code calculates a slightly different formula: $(\widehat \beta_{C,0} - \widehat \beta_{1,0}) + \sum^K_{k=1}\overline X_{C,k}(\widehat \beta_{C,k} - \widehat \beta_{1,k})$. Thus, in the Stata code, the results are multiplied by -1 so that the composition and and structure effects add up to the observed difference. When we calculate the results in Stata, using the formula presented in the paper, our function produces very similar results to the Stata output, with a deviations of less than 0.1 percent in most cases.  

3. Density estimation: For the interquantile ranges the differences are generally larger. We attribute this to the different density estimations in Stata and R (even when using the same kernel function and bandwidth). Specifically, `kdensity` in Stata and `stats::density()` in R set
the grids that define the locus of the density estimates differently. These differences result in different RIF values and thus different regression coefficients. 

**[I would delete this sentence:] Even tough, if the differences are mostly within a few percentages, it indicates that the RIF regression method is less robust for quantiles than for other statistics, since changes in the density estimation have a relatively large impact on the results.**

The bootstrapped standard errors are relatively similar to those reported in the paper. With only 100 bootstrap replications and different seeds, some variance in the terms is not surprising. In addition, we also included the reweighting procedure in the bootstrap estimation, while Fortin et al. only include the RIF regression estimation. 

In summary, our `ob_decompose()` function produces very similar results than those calculated in Stata and presented in the original paper. Using an identical formula, the deviations are mostly below 0.1 percent. However, some values based on RIF estimations of quantiles have slightly higher differences. We have also replicated the results of Table 1-3 in Firpo et al. (2018, p. 21-29), where the differences are generally even smaller. The replication files are available upon request. This validation example illustrates that the `ddecompose` package works as intended in computing reweighted RIF regression decompositions and reliably produces the expected results.

## Credits

David Gallusser & Samuel Meier

## References

Barsky, Robert, John Bound, Kerwin Kofi Charles, and Joseph P. Lupton. 2002. “Accounting for the Black-White Wealth Gap: A Nonparametric Approach.” *Journal of the American Statistical Association* 97: 663–73.

Cowell, Frank A., and Emmanuel Flachaire. 2007. "Income distribution and inequality measurement: The problem of extreme values." *Journal of Econometrics* 141: 1044–1072.

Essama-Nssah, Boniface, and Peter J. Lambert. 2012. “Influence Functions for Policy Impact Analysis.” In John A. Bishop and Rafael Salas, eds., *Inequality, Mobility and Segregation: Essays in Honor of Jacques Silber*. Bigley, UK: Emerald Group Publishing
Limited.

Firpo, Sergio. 2007. "Efficient Semiparametric Estimation of Quantile Treatment Effects." *Econometrica* 75(1): 259-276.

Firpo, Sergio, Nicole M. Fortin, and Thomas Lemieux. 2007a. “Unconditional Quantile Regressions.” *Technical Working Paper 339, National Bureau of Economic Research*. Cambridge, MA. 

Firpo, Sergio, Nicole M. Fortin, and Thomas Lemieux. 2009a. "Unconditional Quantile Regressions." *Econometrica* 77(3): 953-973.

Firpo, Sergio, Nicole M. Fortin, and Thomas Lemieux. 2009b. "Supplement to 'Unconditional Quantile Regressions'." *Econometrica Supplemental Material*, 77.

Firpo, Sergio, Nicole M. Fortin, and Thomas Lemieux. 2018. "Decomposing Wage Distributions Using Recentered Influence Function Regressions." *Econometrics* 6(2):28.

Fortin, Nicole M., Thomas Lemieux, and Sergio Firpo. 2011. "Decomposition Methods in Economics." *National Bureau of Economic Research - Working Paper Series*, 16045.

Firpo, Sergio, and Pinto, Christine. 2016. "Identification and Estimation of Distributional Impacts of Interventions Using Changes in Inequality Measures." *Journal of Applied Econometrics*, 31(3), 457–486. 

Gardeazabal, Javier, and Arantza Ugidos. 2004. "More on identification in detailed wage decompositions." *Review of Economics and Statistics*, 86(4): 1034-1036.

Huber, Martin, Michael Lechner, and Conny Wunsch. 2013. "The performance of estimators based on the propensity score." *Journal of Econometrics* 175(1): 1-21.

Jann, Ben. 2005. "Standard errors for the Blinder-Oaxaca decomposition." *3rd German Stata Users’ Group Meeting 2005*. Available from [https://boris.unibe.ch/69506/1/oaxaca_se_handout.pdf](https://boris.unibe.ch/69506/1/oaxaca_se_handout.pdf).

Jann, Ben. 2008. "The Blinder–Oaxaca Decomposition for Linear Regression Models". *Stata Journal* 8: 435–479.

Kline, Pat. 2009. "Blinder-Oaxaca as a Reweighting Estimator". *UC Berkeley mimeo.*

Rios-Avila, Fernando. 2020. "Recentered influence functions (RIFs) in Stata: RIF regression and RIF decomposition." *The Stata Journal* 20(1): 51-94.

Rothe, Christoph. 2012. "Decomposing the Composition Effect. The Role of Covariates in Determining Between-Group Differences in Economic Outcomes." *IZA Discussion Paper* No. 6397.

Rothe, Christoph. 2015. "Decomposing the Composition Effect. The Role of Covariates in Determining Between-Group Differences in Economic Outcomes." *Journal of Business & Economic Statistics* 33(3): 323-337.



